{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59588986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "759c5494",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     DistilBertTokenizerFast,\n\u001b[32m      5\u001b[39m     DistilBertForSequenceClassification,\n\u001b[32m      6\u001b[39m     TrainingArguments,\n\u001b[32m      7\u001b[39m     Trainer,\n\u001b[32m      8\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from labels import LABELS, label2id, id2label\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99203354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clause</th>\n",
       "      <th>label</th>\n",
       "      <th>source_policy</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Communicate with you We use information we col...</td>\n",
       "      <td>none</td>\n",
       "      <td>youtube_privacy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To have any such information deleted, submit t...</td>\n",
       "      <td>none</td>\n",
       "      <td>hulu_privacy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Because many of our services won’t function wi...</td>\n",
       "      <td>tracking</td>\n",
       "      <td>paypal_privacy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For example, Uber uses identity verification t...</td>\n",
       "      <td>none</td>\n",
       "      <td>uber_driversdelivery_privacy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Car fleet information including capacities is ...</td>\n",
       "      <td>none</td>\n",
       "      <td>priceline_TOS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clause  ... label_id\n",
       "0  Communicate with you We use information we col...  ...        0\n",
       "1  To have any such information deleted, submit t...  ...        0\n",
       "2  Because many of our services won’t function wi...  ...        2\n",
       "3  For example, Uber uses identity verification t...  ...        0\n",
       "4  Car fleet information including capacities is ...  ...        0\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/processed/fineprint_clauses_train_ready.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12c746ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10596, 2650)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df[\"label_id\"],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48880845",
   "metadata": {},
   "source": [
    "## Creating huggingFace dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e039d1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only clause + label_id\n",
    "train_dataset = Dataset.from_pandas(train_df[[\"clause\", \"label_id\"]])\n",
    "test_dataset = Dataset.from_pandas(test_df[[\"clause\", \"label_id\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d16fff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer and model\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bc12883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer function\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"clause\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13913fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10596/10596 [00:00<00:00, 21080.60 examples/s]\n",
      "Map: 100%|██████████| 2650/2650 [00:00<00:00, 22316.13 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(tokenize_batch, batched=True)\n",
    "test_dataset  = test_dataset.map(tokenize_batch, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b21fd96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename only if label_id exists\n",
    "if \"label_id\" in train_dataset.column_names:\n",
    "    train_dataset = train_dataset.rename_column(\"label_id\", \"labels\")\n",
    "\n",
    "if \"label_id\" in test_dataset.column_names:\n",
    "    test_dataset = test_dataset.rename_column(\"label_id\", \"labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c66b602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove hf auto columns\n",
    "# ensures trainer only sees correct columns\n",
    "\n",
    "def drop_index_cols(ds):\n",
    "    idx_cols = [c for c in ds.column_names if c.startswith(\"__\")]\n",
    "    return ds.remove_columns(idx_cols) if idx_cols else ds\n",
    "\n",
    "train_dataset = drop_index_cols(train_dataset)\n",
    "test_dataset  = drop_index_cols(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38c0b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    ")\n",
    "\n",
    "test_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d968b39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load the model \n",
    "\n",
    "num_labels = len(LABELS)\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f31fe5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics function\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    \n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"weighted\", zero_division=0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62e0cf4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# training arguements\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m training_args = \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../models/fineprint-distilbert\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_best_model_at_end\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_for_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mf1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
     ]
    }
   ],
   "source": [
    "# training arguements\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/fineprint-distilbert\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_steps=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "575cca52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.57.3'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4877edc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook transformers version: 4.57.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(\"Notebook transformers version:\", transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b296766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/amulya/Desktop/2025/Coding/FinePrint/FinePrint/.venv/lib/python3.13/site-packages/transformers/training_args.py'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import TrainingArguments\n",
    "import inspect\n",
    "import os\n",
    "\n",
    "file_path = inspect.getfile(TrainingArguments)\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea28be7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
